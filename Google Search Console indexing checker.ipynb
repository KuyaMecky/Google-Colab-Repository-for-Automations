{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from google.oauth2.service_account import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import time\n",
    "import logging\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from openpyxl.styles import PatternFill, Font, Alignment, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "from datetime import datetime\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('wordpress_checker.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Rate limits\n",
    "CALLS_PER_MINUTE = 60\n",
    "ONE_MINUTE = 60\n",
    "\n",
    "@sleep_and_retry\n",
    "@limits(calls=CALLS_PER_MINUTE, period=ONE_MINUTE)\n",
    "def rate_limited_api_call(func):\n",
    "    return func()\n",
    "\n",
    "class WordPressIndexChecker:\n",
    "    def __init__(self, gsc_credentials_file: str, domains: List[str], batch_size: int = 5):\n",
    "        \"\"\"Initialize the WordPress Index Checker.\"\"\"\n",
    "        self.domains = [self._format_domain_url(domain) for domain in domains]\n",
    "        self.batch_size = batch_size\n",
    "        self.credentials = self._load_credentials(gsc_credentials_file)\n",
    "        self.service = build(\"searchconsole\", \"v1\", credentials=self.credentials)\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "\n",
    "    def _load_credentials(self, credentials_file: str) -> Credentials:\n",
    "        \"\"\"Load Google Search Console credentials.\"\"\"\n",
    "        try:\n",
    "            return Credentials.from_service_account_file(\n",
    "                credentials_file,\n",
    "                scopes=[\"https://www.googleapis.com/auth/webmasters\"]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load credentials: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _format_domain_url(self, domain: str) -> str:\n",
    "        \"\"\"Format domain URL with proper scheme.\"\"\"\n",
    "        domain = domain.strip().lower()\n",
    "        if not domain.startswith(('http://', 'https://')):\n",
    "            domain = 'https://' + domain\n",
    "        return domain.rstrip('/')\n",
    "\n",
    "    def _get_site_url(self, url: str) -> str:\n",
    "        \"\"\"Get site URL from any URL.\"\"\"\n",
    "        parsed = urlparse(url)\n",
    "        return f\"{parsed.scheme}://{parsed.netloc}/\"\n",
    "\n",
    "    def get_all_posts(self, domain: str, max_retries: int = 3) -> List[Dict]:\n",
    "        \"\"\"Get all posts from a WordPress domain.\"\"\"\n",
    "        posts = []\n",
    "        page = 1\n",
    "        retries = max_retries\n",
    "        base_url = domain\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                endpoint = f\"{base_url}/wp-json/wp/v2/posts\"\n",
    "                logger.info(f\"Fetching page {page} from: {endpoint}\")\n",
    "\n",
    "                response = self.session.get(\n",
    "                    endpoint,\n",
    "                    params={\n",
    "                        'page': page,\n",
    "                        'per_page': 100,\n",
    "                        'status': 'publish'\n",
    "                    },\n",
    "                    timeout=15\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "\n",
    "                current_posts = response.json()\n",
    "                if not current_posts:\n",
    "                    break\n",
    "\n",
    "                posts.extend(current_posts)\n",
    "                page += 1\n",
    "                retries = max_retries  # Reset retries on success\n",
    "                time.sleep(1)  # Rate limiting\n",
    "\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if response.status_code == 400:\n",
    "                    if response.json().get('code') == 'rest_post_invalid_page_number':\n",
    "                        logger.info(f\"No more pages available for {base_url} (page {page}).\")\n",
    "                        break\n",
    "                    else:\n",
    "                        logger.error(f\"400 Bad Request error encountered for {base_url} (page {page}). Response: {response.text}. Skipping to next domain.\")\n",
    "                        break\n",
    "                else:\n",
    "                    logger.error(f\"Error fetching posts from {base_url} (page {page}, attempt {max_retries - retries + 1}): {e}. Response: {response.text}\")\n",
    "                    retries -= 1\n",
    "                    if retries <= 0:\n",
    "                        logger.error(f\"Max retries reached for {base_url}\")\n",
    "                        break\n",
    "                    time.sleep(2 ** (max_retries - retries))  # Exponential backoff\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                logger.error(f\"Error fetching posts from {base_url} (page {page}, attempt {max_retries - retries + 1}): {e}\")\n",
    "                retries -= 1\n",
    "                if retries <= 0:\n",
    "                    logger.error(f\"Max retries reached for {base_url}\")\n",
    "                    break\n",
    "                time.sleep(2 ** (max_retries - retries))  # Exponential backoff\n",
    "\n",
    "        return posts\n",
    "\n",
    "    def check_google_indexing(self, url: str) -> Optional[bool]:\n",
    "        \"\"\"Check if a URL is indexed in Google Search.\"\"\"\n",
    "        try:\n",
    "            url = self._format_domain_url(url)\n",
    "            site_url = self._get_site_url(url)\n",
    "            \n",
    "            request = self.service.urlInspection().index().inspect(\n",
    "                body={\n",
    "                    \"inspectionUrl\": url,\n",
    "                    \"siteUrl\": site_url\n",
    "                }\n",
    "            )\n",
    "            response = request.execute()\n",
    "            \n",
    "            inspection_result = response.get(\"inspectionResult\", {})\n",
    "            index_status = inspection_result.get(\"indexStatusResult\", {})\n",
    "            coverage_state = index_status.get(\"coverageState\")\n",
    "            \n",
    "            return coverage_state == \"INDEXED\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error checking indexing status for {url}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_single_post(self, domain: str, post: Dict) -> Optional[Dict]:\n",
    "        \"\"\"Process a single WordPress post.\"\"\"\n",
    "        try:\n",
    "            post_title = post.get(\"title\", {}).get(\"rendered\", \"No Title\")\n",
    "            post_url = post.get(\"link\", \"No URL\")\n",
    "            post_date = post.get(\"date\", \"No Date\")\n",
    "            \n",
    "            def check_index():\n",
    "                return self.check_google_indexing(post_url)\n",
    "            \n",
    "            indexed = rate_limited_api_call(check_index)\n",
    "            \n",
    "            days_not_indexed = None\n",
    "            if indexed is False and post_date != \"No Date\":\n",
    "                post_publish_date = datetime.strptime(post_date, \"%Y-%m-%dT%H:%M:%S\")\n",
    "                days_not_indexed = (datetime.now() - post_publish_date).days\n",
    "            \n",
    "            return {\n",
    "                \"Domain\": domain,\n",
    "                \"Post Title\": post_title,\n",
    "                \"Post URL\": post_url,\n",
    "                \"Post Date\": post_date,\n",
    "                \"Indexed\": \"Yes\" if indexed else \"No\" if indexed is False else \"Error\",\n",
    "                \"Days Not Indexed\": days_not_indexed if days_not_indexed is not None else \"N/A\",\n",
    "                \"Check Date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing post {post.get('link', 'Unknown URL')}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def process_single_domain(self, domain: str) -> List[Dict]:\n",
    "        \"\"\"Process all posts from a single domain.\"\"\"\n",
    "        results = []\n",
    "        logger.info(f\"Processing domain: {domain}\")\n",
    "        \n",
    "        posts = self.get_all_posts(domain)\n",
    "        if not posts:\n",
    "            logger.warning(f\"No posts found for domain: {domain}\")\n",
    "            return results\n",
    "            \n",
    "        for post in posts:\n",
    "            try:\n",
    "                post_data = self.process_single_post(domain, post)\n",
    "                if post_data:\n",
    "                    results.append(post_data)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing post in domain {domain}: {e}\")\n",
    "                continue\n",
    "                \n",
    "            time.sleep(1)  # Rate limiting between posts\n",
    "            \n",
    "        return results\n",
    "\n",
    "    def process_domains_in_batches(self) -> pd.DataFrame:\n",
    "        \"\"\"Process all domains in batches.\"\"\"\n",
    "        all_results = []\n",
    "        total_batches = (len(self.domains) + self.batch_size - 1) // self.batch_size\n",
    "        \n",
    "        for i in range(0, len(self.domains), self.batch_size):\n",
    "            batch = self.domains[i:i + self.batch_size]\n",
    "            current_batch = i // self.batch_size + 1\n",
    "            logger.info(f\"Processing batch {current_batch} of {total_batches}\")\n",
    "            \n",
    "            for domain in batch:\n",
    "                try:\n",
    "                    results = self.process_single_domain(domain)\n",
    "                    all_results.extend(results)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing domain {domain}: {e}\")\n",
    "                \n",
    "                time.sleep(2)  # Delay between domains\n",
    "            \n",
    "            if current_batch < total_batches:\n",
    "                logger.info(\"Waiting between batches...\")\n",
    "                time.sleep(10)  # Delay between batches\n",
    "        \n",
    "        return pd.DataFrame(all_results)\n",
    "\n",
    "    def save_excel_report(self, df: pd.DataFrame, output_file: str):\n",
    "        \"\"\"Save results to a formatted Excel report.\"\"\"\n",
    "        if df.empty:\n",
    "            logger.warning(\"No data to save to Excel report\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            writer = pd.ExcelWriter(output_file, engine='openpyxl')\n",
    "            \n",
    "            for domain in df['Domain'].unique():\n",
    "                domain_data = df[df['Domain'] == domain]\n",
    "                sheet_name = urlparse(domain).netloc[:31]  # Excel sheet name length limit\n",
    "                \n",
    "                domain_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                worksheet = writer.sheets[sheet_name]\n",
    "                \n",
    "                # Styling\n",
    "                header_fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')\n",
    "                header_font = Font(color='FFFFFF', bold=True)\n",
    "                border = Border(\n",
    "                    left=Side(style='thin'), \n",
    "                    right=Side(style='thin'),\n",
    "                    top=Side(style='thin'), \n",
    "                    bottom=Side(style='thin')\n",
    "                )\n",
    "                \n",
    "                # Format headers\n",
    "                for col in range(1, len(domain_data.columns) + 1):\n",
    "                    cell = worksheet.cell(row=1, column=col)\n",
    "                    cell.fill = header_fill\n",
    "                    cell.font = header_font\n",
    "                    cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "                    cell.border = border\n",
    "                    \n",
    "                    # Auto-adjust column width\n",
    "                    column_letter = get_column_letter(col)\n",
    "                    max_length = max(\n",
    "                        len(str(domain_data.columns[col-1])),\n",
    "                        domain_data[domain_data.columns[col-1]].astype(str).map(len).max()\n",
    "                    )\n",
    "                    adjusted_width = min(max_length + 2, 50)  # Cap width at 50\n",
    "                    worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "                \n",
    "                # Format data cells\n",
    "                for row in range(2, len(domain_data) + 2):\n",
    "                    for col in range(1, len(domain_data.columns) + 1):\n",
    "                        cell = worksheet.cell(row=row, column=col)\n",
    "                        cell.border = border\n",
    "                        cell.alignment = Alignment(horizontal='left', vertical='center')\n",
    "                        \n",
    "                        # Color coding for Indexed column\n",
    "                        if domain_data.columns[col-1] == 'Indexed':\n",
    "                            value = cell.value\n",
    "                            if value == 'Yes':\n",
    "                                cell.fill = PatternFill(start_color='C6EFCE', end_color='C6EFCE', fill_type='solid')\n",
    "                            elif value == 'No':\n",
    "                                cell.fill = PatternFill(start_color='FFC7CE', end_color='FFC7CE', fill_type='solid')\n",
    "                            elif value == 'Error':\n",
    "                                cell.fill = PatternFill(start_color='FFEB9C', end_color='FFEB9C', fill_type='solid')\n",
    "            \n",
    "            writer.close()\n",
    "            logger.info(f\"Excel report saved successfully to {output_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save Excel report: {e}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    GSC_CREDENTIALS_FILE = \"/content/wordpress-index-checker-448410-4533712f0b6d.json\"\n",
    "    DOMAINS = [\n",
    "        \"tclottery-app.in\",\n",
    "\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Initialize checker with batch processing\n",
    "        checker = WordPressIndexChecker(GSC_CREDENTIALS_FILE, DOMAINS, batch_size=5)\n",
    "        \n",
    "        # Process all domains and get results\n",
    "        results_df = checker.process_domains_in_batches()\n",
    "        \n",
    "        if not results_df.empty:\n",
    "            # Generate output filename with timestamp\n",
    "            output_file = f\"{DOMAINS}_wordpress_indexing_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "            \n",
    "            # Save the report\n",
    "            checker.save_excel_report(results_df, output_file)\n",
    "            logger.info(f\"Report generated successfully: {output_file}\")\n",
    "        else:\n",
    "            logger.warning(\"No data was collected. Please check if the domains are accessible.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Script execution failed: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
